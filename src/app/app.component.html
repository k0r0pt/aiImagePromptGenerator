<h1>k0r0pt AI Image Prompt Generator</h1>
<mat-divider></mat-divider>
<div class="linksGrid">
  <div id="githubLink"><mat-icon color="primary" [svgIcon]="'github'"></mat-icon>&nbsp;<b><a href="https://github.com/k0r0pt/aiImagePromptGenerator">Github</a></b></div>
  <div id="runLink"><mat-icon color="primary">home</mat-icon>&nbsp;<b><a href="https://k0r0pt-ai-image-prompt-gen.sudipto.me">Run</a></b></div>
  <div id="buildStatusLink"><a href="https://github.com/k0r0pt/aiImagePromptGenerator/actions/workflows/build.yml"><img src="https://github.com/k0r0pt/aiImagePromptGenerator/actions/workflows/build.yml/badge.svg" /></a></div>
</div>
<mat-divider></mat-divider>
<br />
<br />
<b>NOTE</b>: You'll need to install <a href="https://ollama.com/">Ollama</a>, and then install and run Llama3.1 - <code>ollama run llama3.1</code>, for this to work.
<br />
Alternatively, you can expand the <code>LLM Options</code> in the third panel to specify your Ollama server.
<br />
<div *ngIf="runningOnServer">You also need to set this environment variable so that your Ollama can be accessed from the browser when you're visiting this site (yes, we'll be working on better ways of doing this) - <code color="primary">OLLAMA_ORIGINS={{origin}}</code></div>
<br />
<br />
<br />
<mat-divider></mat-divider>
<div class="grid">
  <div id="leftPanel"><app-settings-specifier></app-settings-specifier></div>
  <div id="midPanel"><app-prompt-gen></app-prompt-gen></div>
  <div id="rightPanel"><app-llm-prompt-gen></app-llm-prompt-gen></div>
</div>